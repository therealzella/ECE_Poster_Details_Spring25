# Evaluating Multitask Reasoning in Large Language Models and Extending to AI-Agent-based Question Answering 

This repository contains code and resources for the ECE Spring 2025 Poster Presentation. The project is based on ECE590 course project and explores the multitask reasoning capabilities of large language models (LLMs) and extends the evaluation pipeline to include an AI-agent-based system for question answering.

## ğŸ§  Project Overview

Recent advancements in LLMs demonstrate promising capabilities in handling multiple tasks simultaneously, particularly in zero-shot and few-shot settings. This project:

- Evaluates LLMs on multitask reasoning using the MMLU (Massive Multitask Language Understanding) dataset.
- Analyzes strengths and limitations in reasoning performance across domains.
- Proposes an extension using a retrieval-augmented AI agent system (LangChain + OpenAI) for real-time, domain-adaptive question answering.

## ğŸ“ Repository Structure

```bash
.
â”œâ”€â”€ AI_agent_for_poster.ipynb         # LangChain + OpenAI agent-based QA implementation
â”œâ”€â”€ annotated-ECE590_LLM_Final_Project_Coding.pdf  # Annotated final project code version
â”œâ”€â”€ README.md                         # Project documentation
